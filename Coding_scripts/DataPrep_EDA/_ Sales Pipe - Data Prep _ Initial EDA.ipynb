{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58257323-e76b-4c9b-8159-9294dc3117d4",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# This Notebook is used for initial data exploration and filtering for the sales machine learning project.\n",
    "\n",
    "Most of the EDA has been done using simple print statements, hence not being saved to the script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae3aac6-2f44-4053-a1bc-457109708987",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Function to make sure the script autostops, in case of wrong lakehouse destination\n",
    "\n",
    "def lakehouse_gatekeep(expected_db = \"ml_curate_lakehouse\"):\n",
    "    db = spark.catalog.currentDatabase()\n",
    "\n",
    "    if db != expected_db:\n",
    "       raise Exception(\n",
    "        f\"Forkert Lakehouse er tilkoblet som default: '{db}'.\"\n",
    "        f\"Det rigtige lakehouse er: '{expected_db}'. Sæt default lakehouse til '{expected_db}' i Explorer i venstre side.\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Det korrekte lakehouse: '{db}' er valgt. scriptet fortsættes\")\n",
    "\n",
    "lakehouse_gatekeep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ce001f-cc4b-481e-a569-5c2c24ac1741",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "#### dependencies ####\n",
    "spark.conf.set(\"spark.sql.parquet.datetimeRebaseModeInRead\", \"LEGACY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865cfa28-072e-4de2-8f8b-d07cbe0eb0b4",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "#### Installs if required ####\n",
    "\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b476fc0d-93e8-4245-bfc2-7ade82717438",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "#### Imports ####\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73da69e-529a-4664-9d0b-7450a82e0eb0",
   "metadata": {
    "advisor": {
     "adviceMetadata": "{\"artifactId\":\"98316d21-e6b9-4687-9444-0fcd7cab9627\",\"activityId\":\"91ec8b3b-e1d1-409e-bdab-e8629a9139b8\",\"applicationId\":\"application_1767129838128_0001\",\"jobGroupId\":\"7\",\"advices\":{\"warn\":2}}"
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    \"TrackBatchID\",\n",
    "    \"AnalysisKey\",\n",
    "    \"BusinessUnitKey\",\n",
    "    \"DW_Batch_Created\",\n",
    "    \"DealSizeKey\",\n",
    "    \"DW_ID\",\n",
    "    \"EmployeeKey\",\n",
    "    \"LeadCreateDate\",\n",
    "    \"LeadCreateDateTime\",\n",
    "    \"LeadKey\",\n",
    "    \"MovementTypeCRMKey\",\n",
    "    # \"OpportunityKey\",  # KEEP\n",
    "    \"OpportunityStatusKey\",\n",
    "    \"PipelineDate\",\n",
    "    \"PrimoDate\",\n",
    "    \"ReasonKey\",\n",
    "    \"RevenueTypeKey\",\n",
    "    \"SalesMotionKey\",\n",
    "    \"SalesStageKey\",\n",
    "    \"SourceKey\",\n",
    "    \"TechnologyKey\",\n",
    "    \"WhiteSpot\",\n",
    "    \"WinChanceKey\",\n",
    "    \"PartitionBy\",\n",
    "    \"CRMActionPlanDetailsStatus\",\n",
    "    \"CRMActionPlanDetailsKey\",\n",
    "    \"CRMCustomerKey\",\n",
    "    \"CRMIndustryKey\",\n",
    "    \"CRMVendorKey\",\n",
    "    \"CurrencyKey\",\n",
    "    \"CustomerVoiceAlertKey\",\n",
    "    \"CampaignMembersKey\",\n",
    "    \"ConsciaCountryKey\",\n",
    "    \"CRMBusinessAreaKey\",\n",
    "    \"NPSKey\",\n",
    "    \"OpportunityDatesKey\",\n",
    "    \"OpportunityGroupKey\",\n",
    "    \"OpportunityLineKey\",\n",
    "    \"OpportunityStateKey\",\n",
    "    \"PipelineBreakdownKey\",\n",
    "    \"NoOfLeads\",\n",
    "    \"NoOfNPSRespons\",\n",
    "    \"NoOfOpportunities\",\n",
    "    \"NoOfOpportunityLines\",\n",
    "    \"NoTransactions\",\n",
    "    \"NPSRating\",\n",
    "    \"NPSRatingDetractor\",\n",
    "    \"NPSRatingPassive\",\n",
    "    \"NPSRatingPromoter\",\n",
    "    \"NPSStatus\",\n",
    "    \"NPSType\",\n",
    "    \"CRMActionPlanDetailsCounter\",\n",
    "    \"OpportunityRevenueDKK\",\n",
    "    \"LeadTechnology\",\n",
    "    \"CurrencyID\",\n",
    "    \"DevelopDate\",\n",
    "    \"OfferDate\",\n",
    "    \"NegotiateDate\",\n",
    "    # \"CloseDate\",  # KEEP\n",
    "    \"DaysBetweenQualifyDevelop\",\n",
    "    \"DaysBetweenDevelopOffer\",\n",
    "    \"DaysBetweenOfferNegotiate\",\n",
    "    \"DaysBetweenNegotiateClose\",\n",
    "    # \"Period\",  # KEEP\n",
    "    \"WeigthedOpportunityRevenueDKK\",\n",
    "    \"PipelineBreakdownValueDKK\",\n",
    "    \"LeadsTotalContractValueDKK\",\n",
    "    \"Date\",\n",
    "    \"SubType2\",\n",
    "    \"CRMBusinessLine\",\n",
    "    \"CRMServiceOffering\",\n",
    "    \"CRMBusinessService\",\n",
    "    # \"OpportunityStatusActual\",  # KEEP\n",
    "    # \"SalesStageName\",  # KEEP\n",
    "    # \"LeadQuality\",  # KEEP\n",
    "    # \"DaysInStage\",  # KEEP\n",
    "    # \"EstimatedInvoiceDate\",  # KEEP\n",
    "    \"SecurityCountry\",\n",
    "    # \"WinChanceNumber\",  # KEEP\n",
    "    \"Fact_DW_ID\"\n",
    "]\n",
    "\n",
    "sales_raw_spark = (\n",
    "    spark.read.table(\"Sales_ml_raw\")\n",
    "    .filter(\"CalendarDate IS NULL OR CalendarDate >= '2010-01-01'\")\n",
    "    .drop(*cols_to_drop)\n",
    ")\n",
    "\n",
    "sales_raw = sales_raw_spark.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06271e0-f4f7-484a-8654-70274a88c747",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "sales_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840ae235-64cc-4540-8f25-69d4b1361128",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "#### Feature Engineering ####\n",
    "\n",
    "    # Creating relevant new features from existing irrelevant features. \n",
    "\n",
    "    # - Monthly Column instead of CalendarDate\n",
    "sales_raw['MonthName'] = pd.to_datetime(sales_raw['CalendarDate'], format='%m/%d/%Y, %I:%M:%S %p', errors='coerce').dt.strftime('%B')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff19558a-185a-4b39-93b7-1bd98b1645b7",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "## Importing the budget manually with Minhs excel extract\n",
    "    # - Need to find a smarter way if its intended to be used in prod due to dynamically changing targets\n",
    "        # -- Perhaps a dynamically changing xcel spreadsheet where the formats the same\n",
    "\n",
    "Budget = pd.DataFrame({\n",
    "\n",
    "    \"År\": [2024, 2024, 2024, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025],\n",
    "    \"Måned\": ['October', 'November', 'December', 'January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September'], \n",
    "    \"Actual_sol\": [329375.14, 323324.67, 485635.66, 309851.72, 300083.53, 336556.5, 302158.6, 305358.2, 443289.2, 447492.9, 9624.7, 0.0],\n",
    "    \"Target_sol\": [328937.7, 333129.8, 343623.8, 402712.9, 387175.9, 351229.9, 332012.9, 336120.7, 393550.4, 345422.9, 311976.1, 347876.4],\n",
    "    \"Actual_serv\": [42041, 40099, 163547.9, 180604.5, 83752.6, 85229, 40848.2, 46575.4, 66572.8, 196346.8, 744.3, 0.0],\n",
    "    \"Target_serv\": [49849.7, 56836.4, 117174.2, 148085.4, 83974.6, 80901.6, 77190.2, 70956.8, 73592.8, 113783.5, 65380.5, 101896.1]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22314b4d-f76e-4182-bc4e-aa7bd7792dc6",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "#### Data cleaning ####\n",
    "\n",
    "    # Removing duplicates, NA-values, irrelevant columns and creating filters\n",
    "\n",
    "sales_raw = sales_raw.drop_duplicates()\n",
    "\n",
    "        # Removing every row with negative OpportunityID (seems to be non-specific opps.)\n",
    "\n",
    "sales_raw = sales_raw[sales_raw['OpportunityKey'] >= 0]\n",
    "#sales_raw = sales_raw[sales_raw['OpportunityStatusGroup'] == \"Closed\"]\n",
    "\n",
    "\n",
    "# Generalizing sales stage down to closed / open\n",
    "\n",
    "sales_raw['OpportunityStatusGroup'] = sales_raw['OpportunityStatusGroup'].apply(lambda x: 'Closed' if 'Closed' in x else 'Open')\n",
    "\n",
    "\n",
    "# Config NAs\n",
    "\n",
    "sales_raw[['NxoLeadStatus', 'LeadQuality', 'LeadStatus', 'LeadStage']] = sales_raw[['NxoLeadStatus', 'LeadQuality', 'LeadStatus', 'LeadStage']].replace(\"NA\", \"Not a lead\")\n",
    "\n",
    "sales_raw[['OpportunityStatusActual', 'WinChanceGroup']] = sales_raw[['OpportunityStatusActual', 'WinChanceGroup']].replace(\"NA\", \"Its a lead\")\n",
    "\n",
    "sales_raw['TechnologyName'] = sales_raw['TechnologyName'].replace(\"NA\", \"Other\")\n",
    "\n",
    "sales_raw[['Title', 'Site', 'Department', 'EmployeeName', 'OpportunityConsciaCountry', 'OpportunitySalesTeam']] = sales_raw[['Title', 'Site', 'Department', 'EmployeeName', 'OpportunityConsciaCountry', 'OpportunitySalesTeam']].replace(\"NA\", \"Not stated\")\n",
    "\n",
    "sales_raw['YearName'] = sales_raw['PeriodName'].str.extract(r'(\\d{4})').astype(int)\n",
    "\n",
    "sales_raw = sales_raw[sales_raw['DealSizeName'].notna() & (sales_raw['DealSizeName'] != \"NA\")] \n",
    "\n",
    "## Filteirng out loads of NA columns (probably fom misclicks in CRM, committing faulty data entries)\n",
    "\n",
    "sales_raw = sales_raw[sales_raw['RevenueType'] != 'NA']\n",
    "\n",
    "# Converting to absolute values\n",
    "\n",
    "\n",
    "sales_raw['DaysToClose'] = sales_raw['DaysToClose'].abs()\n",
    "\n",
    "# Columndropping\n",
    "\n",
    "sales_clean = sales_raw.drop(columns = {\n",
    "    'OpportunityKey',\n",
    "    'OpportunityStatusActual',\n",
    "    'LeadQuality',\n",
    "    'CloseDate',\n",
    "    'Period',\n",
    "    'SalesStageName',\n",
    "    'DaysInStage',\n",
    "    'EstimatedInvoiceDate',\n",
    "    'WinChanceNumber'\n",
    "})\n",
    "\n",
    "    # Dropping different currency values (Keeping it separate incase i want to swap currency later)\n",
    "sales_clean = sales_clean.drop(columns = {\n",
    "    #ACV\n",
    "    'AnnualContractValueEUR',\n",
    "    'AnnualContractValueGBP',\n",
    "    'AnnualContractValueLocal',\n",
    "    'AnnualContractValueNOK',\n",
    "    'AnnualContractValueSEK',\n",
    "    'AnnualContractValueUSD',\n",
    "    #LeadTCV\n",
    "    'LeadsTotalContractValueEUR',\n",
    "    'LeadsTotalContractValueGBP',\n",
    "    'LeadsTotalContractValueLocal',\n",
    "    'LeadsTotalContractValueNOK',\n",
    "    'LeadsTotalContractValueSEK',\n",
    "    'LeadsTotalContractValueUSD',\n",
    "    #Margins\n",
    "    'MarginValueEUR',\n",
    "    'MarginValueGBP',\n",
    "    'MarginValueLocal',\n",
    "    'MarginValueNOK',\n",
    "    'MarginValueSEK',\n",
    "    'MarginValueUSD',\n",
    "    #PipelineBreakdownValue,\n",
    "    'PipelineBreakdownValueEUR',\n",
    "    'PipelineBreakdownValueGBP',\n",
    "    'PipelineBreakdownValueLocal',\n",
    "    'PipelineBreakdownValueNOK',\n",
    "    'PipelineBreakdownValueSEK',\n",
    "    'PipelineBreakdownValueUSD',\n",
    "    #TCV,\n",
    "    'TotalContractValueEUR',\n",
    "    'TotalContractValueGBP',\n",
    "    'TotalContractValueLocal',\n",
    "    'TotalContractValueNOK',\n",
    "    'TotalContractValueSEK',\n",
    "    'TotalContractValueUSD',\n",
    "    #WeightedACV\n",
    "    'WeightedAnnualContractValueEUR',\n",
    "    'WeightedAnnualContractValueGBP',\n",
    "    'WeightedAnnualContractValueLocal',\n",
    "    'WeightedAnnualContractValueNOK',\n",
    "    'WeightedAnnualContractValueSEK',\n",
    "    'WeightedAnnualContractValueUSD',\n",
    "    #WeightedMargin\n",
    "    'WeigthedMarginValueEUR',\n",
    "    'WeigthedMarginValueGBP',\n",
    "    'WeigthedMarginValueLocal',\n",
    "    'WeigthedMarginValueNOK',\n",
    "    'WeigthedMarginValueSEK',\n",
    "    'WeigthedMarginValueUSD',\n",
    "    #WeightedOpportunityRevenue\n",
    "    'WeigthedOpportunityRevenueEUR',\n",
    "    'WeigthedOpportunityRevenueGBP',\n",
    "    'WeigthedOpportunityRevenueLocal',\n",
    "    'WeigthedOpportunityRevenueNOK',\n",
    "    'WeigthedOpportunityRevenueSEK',\n",
    "    'WeigthedOpportunityRevenueUSD',\n",
    "    #WeightedTCV\n",
    "    'WeigthedTotalContractValueEUR',\n",
    "    'WeigthedTotalContractValueGBP',\n",
    "    'WeigthedTotalContractValueLocal',\n",
    "    'WeigthedTotalContractValueNOK',\n",
    "    'WeigthedTotalContractValueSEK',\n",
    "    'WeigthedTotalContractValueUSD',\n",
    "    #OpportunityRevenue\n",
    "    'OpportunityRevenueEUR',\n",
    "    'OpportunityRevenueGBP',\n",
    "    'OpportunityRevenueLocal',\n",
    "    'OpportunityRevenueNOK',\n",
    "    'OpportunityRevenueSEK',\n",
    "    'OpportunityRevenueUSD',\n",
    "    # Might need to get readded\n",
    "    #'WeigthedMarginValueDKK',\n",
    "    #'WeightedAnnualContractValueDKK',\n",
    "    #'WeigthedTotalContractValueDKK'\n",
    "\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93841d8-a2f8-4b24-afc0-16f041afc147",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "sales_clean['OpportunityStatusGroup'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b73130c-b9b0-4677-9dfe-45bfeb28e803",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Reordering columns for overview\n",
    "sales_clean = sales_clean[\n",
    "    [\n",
    "       'OpportunityStatusGroup', 'CRMBusinessArea', 'OpportunityID', 'OpportunityNumber','OpportunityName', 'OpportunityState','TotalContractValueDKK', 'AnnualContractValueDKK',\n",
    "        'MarginValueDKK',\n",
    "\n",
    "        'CalendarDate', 'PeriodName', 'MonthName', 'YearName', 'CreatedDate', 'QualifyDate', 'ActualClosedDate',\n",
    "\n",
    "        \"EmployeeName\", \"Title\", \"Department\", \"Site\",\n",
    "\n",
    "        'CurrentSalesStage', 'OpportunityConsciaCountry',\n",
    "        'OpportunitySalesTeam', 'DaysBetweenCreateClose', 'RevenueType', 'SubType',\n",
    "\n",
    "        'LeadStage', 'LeadStatus', 'NxoLeadStatus',\n",
    "\n",
    "        'DaysToClose', 'DealSizeName', 'IndustryName',\n",
    "        'OpportunityStatusActualGroup',\n",
    "        'SecurityCountryName', 'TechnologyName', 'WinChanceName', 'WinChanceGroup', 'EstimatedCloseDate'\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2000ffa-41fd-4809-ab26-481729581721",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "sales_lead = sales_clean[sales_clean['LeadStatus'] != 'Not a lead']\n",
    "sales_opp = sales_clean[sales_clean['LeadStatus'] == 'Not a lead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e551f232-3180-4261-88dd-0401176fb006",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Flattening Feature engineering to not lose lead and stage information about opportunities: \n",
    "\n",
    "\n",
    "         # does the opp. stem from a lead?\n",
    "sales_opp['FromLead'] = sales_opp['OpportunityNumber'].isin(sales_lead['OpportunityNumber']).map({True: 'Yes', False: 'No'})\n",
    "\n",
    "\n",
    "\n",
    "        # Days Between Marketing Qualified Lead - Sales Qualified Lead (essentially capturing the span of the lead duration)\n",
    "\n",
    "        # Doesnt work as its somehow dimensionally enhanced?.., and leads dont seem to be important (Minhs words) so removed for now\n",
    "#lead_span = ( sales_lead.groupby('OpportunityNumber')['CalendarDate'].agg(['min', 'max']) .reset_index())\n",
    "#lead_span['DaysBetweenMQL_SQL'] = (lead_span['max'] - lead_span['min']).dt.days\n",
    "\n",
    "#sales_opp = sales_opp.merge(lead_span[['OpportunityNumber', 'DaysBetweenMQL_SQL']], on = 'OpportunityNumber', how = 'left')\n",
    "\n",
    "#sales_opp['DaysBetweenMQL_SQL'] = sales_opp['DaysBetweenMQL_SQL'].fillna(-1)\n",
    "\n",
    "\n",
    "# turning every monetary column into absolute values \n",
    "\n",
    "mon_cols = [\n",
    "    'TotalContractValueDKK',\n",
    "   # 'WeigthedMarginValueDKK',\n",
    "    'AnnualContractValueDKK',\n",
    "   #'WeightedAnnualContractValueDKK',\n",
    "    #'WeigthedTotalContractValueDKK',\n",
    "    'MarginValueDKK'\n",
    "]\n",
    "\n",
    "sales_opp[mon_cols] = sales_opp[mon_cols].abs()\n",
    "\n",
    "## A lot of config for WinChance cols\n",
    "\n",
    "sales_opp['PeriodDate'] = pd.to_datetime(sales_opp['PeriodName'], format='%B %Y')\n",
    "sales_opp = sales_opp.sort_values(by=['OpportunityNumber', 'PeriodDate'])\n",
    "\n",
    "sales_opp['WinChanceNum'] = (\n",
    "    sales_opp['WinChanceName']\n",
    "    .astype(str)\n",
    "    .str.extract(r'(\\d+)\\s?%')[0]\n",
    "    .astype(float)\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "Actual_WinChance = (\n",
    "    sales_opp[sales_opp['OpportunityState'] == 'Won']\n",
    "    .sort_values(by=['OpportunityNumber', 'PeriodDate'])\n",
    "    .groupby('OpportunityNumber')['WinChanceNum']\n",
    "    .first()\n",
    "    .reset_index()\n",
    "    .rename(columns={'WinChanceNum': 'ActualWinChance'})\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c39d0e-a0e3-4b21-b9e9-ad3d04fb2f64",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "sales_flattened = sales_opp[sales_opp['OpportunityStatusGroup'] == 'Closed']\n",
    "\n",
    "# Grundet diverse data entries pr. cloesd row (tror det CRM dupe fejl) er det nødsaget at filtrere mere manuelt gennem PeriodName\n",
    "\n",
    "sales_flattened['PeriodDate'] = pd.to_datetime(sales_flattened['PeriodName'], format = '%B %Y')\n",
    "sales_flattened_sorted = sales_flattened.sort_values(by = ['OpportunityNumber', 'PeriodDate'], ascending = [True, False])\n",
    "sales_flattened = sales_flattened_sorted.drop_duplicates(subset = 'OpportunityNumber', keep = 'first')\n",
    "\n",
    "## Flattening out the WinChance columns to eliminate dataleakage\n",
    "        # In addition, the winchance suffers from extreme amounts of label leakage, as the latest dataentry for a opportunity is typically set to 100% winchance once the opportunity is won, although thats not the winchance that was current, when the opportunity was won. \n",
    "                # As I dont want the model to learn from artificially inflated datapoints, I'll rearrange the winchance data to include summary-like variables and the correct winchance at the moment the opportunity got marked as won. \n",
    "                    # Once again, in addition to that, The winChance is labelproxy, essentially describibing what im trying to predict. This can cause the model to be very reliant on this specific feature, therefore splitting it into a summary is generally very good. \n",
    "\n",
    "def winchance_summarised(group):\n",
    "    group = group.sort_values('PeriodDate') \n",
    "    WinChance = group['WinChanceNum'].astype(float).values\n",
    "    dates = group['PeriodDate']\n",
    "    days = (dates - dates.iloc[0]).dt.days\n",
    "\n",
    "    max_win = WinChance.max()\n",
    "\n",
    "    won_rows = group[group['OpportunityState'] == 'Won']\n",
    "    current_win = won_rows['WinChanceNum'].iloc[0] if not won_rows.empty else WinChance[-1]\n",
    "\n",
    "    return pd.Series({\n",
    "        'MinWinChance': WinChance.min(),\n",
    "        'MaxWinChance': max_win,\n",
    "        'stdWinChance': WinChance.std(),\n",
    "        'CurrentWinChance': current_win,\n",
    "        'IsCurrentWinChanceMax': current_win == max_win,\n",
    "        'WinChanceDropFromMax': max_win - current_win\n",
    "    })\n",
    "\n",
    "summary_opp = sales_opp.groupby('OpportunityNumber').apply(winchance_summarised).reset_index()\n",
    "\n",
    "sales_flattened = sales_flattened.merge(summary_opp, on = 'OpportunityNumber', how = \"left\")\n",
    "\n",
    "# sales_flattened = sales_flattened.drop(columns = 'PeriodDate')\n",
    "\n",
    "sales_flattened = sales_flattened.merge(Actual_WinChance, on='OpportunityNumber', how='left')\n",
    "sales_flattened['ActualWinChance'] = sales_flattened.apply(\n",
    "    lambda row: row['ActualWinChance'] if row['OpportunityState'] == 'Won' else row['WinChanceNum'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Fjerner de resterende blanke og missing opps.\n",
    "\n",
    "sales_flattened = sales_flattened[\n",
    "    sales_flattened['OpportunityNumber'].notna() &\n",
    "    (sales_flattened['OpportunityNumber'].astype(str).str.strip().str.upper() != 'NA') &\n",
    "    (sales_flattened['OpportunityNumber'].astype(str).str.strip() != '')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36872420-5216-48d5-9a6d-d78fed38c563",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Removing potential dataleakage and the last unnessecary cols\n",
    "\n",
    "sales_flattened = sales_flattened.drop(columns = {\n",
    "    'DaysToClose',\n",
    "    #'CreatedDate',\n",
    "    'QualifyDate',\n",
    "    #'ActualClosedDate',\n",
    "    'CurrentSalesStage',\n",
    "    'RevenueType',\n",
    "    'OpportunityStatusActualGroup',\n",
    "        # No opps with leads after filtering\n",
    "    'LeadStatus',\n",
    "    'NxoLeadStatus',\n",
    "    'FromLead',\n",
    "    'LeadStage',\n",
    "    'CurrentWinChance',\n",
    "    'WinChanceNum',\n",
    "    'WinChanceName',\n",
    "    'WinChanceGroup',\n",
    "    \n",
    "})\n",
    "\n",
    "sales_flattened.rename(columns = {\n",
    "    'ActualWinChance': 'WinChance'\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f734eea-799a-46ce-a842-6990a68d447f",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "solutions_raw = sales_flattened[sales_flattened['CRMBusinessArea'] == \"Solutions\"]\n",
    "service_raw = sales_flattened[sales_flattened['CRMBusinessArea'] == \"Services\"]\n",
    "\n",
    "solutions_ml = solutions_raw.drop(columns = {\n",
    "    'CRMBusinessArea',\n",
    "    'OpportunityID',\n",
    "    'OpportunityName',\n",
    "    #'CalendarDate',\n",
    "    'MaxWinChance',\n",
    "    'ActualWinChance',\n",
    "    'WinChanceDropFromMax',\n",
    "    'MinWinChance',\n",
    "    'stdWinChance',\n",
    "    'IsCurrentWinChanceMax',\n",
    "    'PeriodName',\n",
    "    'SecurityCountryName'\n",
    "\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Define the columns and their intended data types\n",
    "Dtypes_to_change = {\n",
    "    'TotalContractValueDKK': 'float',       \n",
    "    'AnnualContractValueDKK': 'float',\n",
    "    'MarginValueDKK': 'float',\n",
    "    #'PeriodName': 'category',\n",
    "    'MonthName': 'category',\n",
    "    'EmployeeName': 'category',\n",
    "    'Title': 'category',\n",
    "    'Department': 'category',\n",
    "    'Site': 'category',\n",
    "    'OpportunityStatusGroup': 'category',\n",
    "    'OpportunityConsciaCountry': 'category',\n",
    "    'OpportunitySalesTeam': 'category',\n",
    "    'SubType': 'category',\n",
    "    'DealSizeName': 'category',\n",
    "    'IndustryName': 'category',\n",
    "    'TechnologyName': 'category',\n",
    "    'YearName': 'category'\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "# Apply the dtype conversions\n",
    "for column, dtype in Dtypes_to_change.items():\n",
    "    try:\n",
    "        solutions_ml[column] = solutions_ml[column].astype(dtype)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not convert {column} to {dtype}: {e}\")\n",
    "\n",
    "\n",
    "solutions_ml['DaysBetweenCreateClose'] = solutions_ml['DaysBetweenCreateClose'].abs()\n",
    "\n",
    "otherCRM_opps = solutions_ml.loc[\n",
    "    solutions_ml['DaysBetweenCreateClose'] == 0,\n",
    "    'OpportunityNumber'\n",
    "].tolist()\n",
    "\n",
    "solutions_ml = solutions_ml[solutions_ml['DaysBetweenCreateClose'] != 0]\n",
    "\n",
    "solutions_ml = solutions_ml[solutions_ml['TotalContractValueDKK'] != 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d8a21d-84ec-4e70-b490-76ba14827bf9",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "solutions_ml.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5227ae-1cbc-4743-9dbf-dc972e12bf40",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "#### Script copy but for active opportunities ####\n",
    "##################################################\n",
    "\n",
    "sales_flattened_active = sales_opp[sales_opp['OpportunityStatusGroup'] == 'Open']\n",
    "\n",
    "\n",
    "sales_flattened_active['PeriodDate'] = pd.to_datetime(sales_flattened_active['PeriodName'], format = '%B %Y')\n",
    "sales_flattened_active_sorted = sales_flattened_active.sort_values(by = ['OpportunityNumber', 'PeriodDate'], ascending = [True, False])\n",
    "sales_flattened_active = sales_flattened_active_sorted.drop_duplicates(subset = 'OpportunityNumber', keep = 'first')\n",
    "\n",
    "## Flattening out the WinChance columns to eliminate dataleakage\n",
    "        # In addition, the winchance suffers from extreme amounts of label leakage, as the latest dataentry for a opportunity is typically set to 100% winchance once the opportunity is won, although thats not the winchance that was current, when the opportunity was won. \n",
    "                # As I dont want the model to learn from artificially inflated datapoints, I'll rearrange the winchance data to include summary-like variables and the correct winchance at the moment the opportunity got marked as won. \n",
    "                    # Once again, in addition to that, The winChance is labelproxy, essentially describibing what im trying to predict. This can cause the model to be very reliant on this specific feature, therefore splitting it into a summary is generally very good. \n",
    "\n",
    "\n",
    "\n",
    "sales_flattened_active = sales_flattened_active.merge(summary_opp, on = 'OpportunityNumber', how = \"left\")\n",
    "\n",
    "# sales_flattened_active = sales_flattened_active.drop(columns = 'PeriodDate')\n",
    "\n",
    "sales_flattened_active = sales_flattened_active.merge(Actual_WinChance, on='OpportunityNumber', how='left')\n",
    "sales_flattened_active['ActualWinChance'] = sales_flattened_active.apply(\n",
    "    lambda row: row['ActualWinChance'] if row['OpportunityState'] == 'Won' else row['WinChanceNum'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Fjerner de resterende blanke og missing opps.\n",
    "\n",
    "sales_flattened_active = sales_flattened_active[\n",
    "    sales_flattened_active['OpportunityNumber'].notna() &\n",
    "    (sales_flattened_active['OpportunityNumber'].astype(str).str.strip().str.upper() != 'NA') &\n",
    "    (sales_flattened_active['OpportunityNumber'].astype(str).str.strip() != '')\n",
    "]\n",
    "\n",
    "\n",
    "# Removing potential dataleakage and the last unnessecary cols\n",
    "\n",
    "sales_flattened_active = sales_flattened_active.drop(columns = {\n",
    "    'DaysToClose',\n",
    "    #'CreatedDate',\n",
    "    'QualifyDate',\n",
    "    #'ActualClosedDate',\n",
    "    'CurrentSalesStage',\n",
    "    'RevenueType',\n",
    "    'OpportunityStatusActualGroup',\n",
    "        # No opps with leads after filtering\n",
    "    'LeadStatus',\n",
    "    'NxoLeadStatus',\n",
    "    'FromLead',\n",
    "    'LeadStage',\n",
    "    'CurrentWinChance',\n",
    "    'WinChanceNum',\n",
    "    'WinChanceName',\n",
    "    'WinChanceGroup'\n",
    "})\n",
    "\n",
    "sales_flattened_active.rename(columns = {\n",
    "    'ActualWinChance': 'WinChance'\n",
    "})\n",
    "\n",
    "solutions_raw_active = sales_flattened_active[sales_flattened_active['CRMBusinessArea'] == \"Solutions\"]\n",
    "service_raw_active = sales_flattened_active[sales_flattened_active['CRMBusinessArea'] == \"Services\"]\n",
    "\n",
    "solutions_ml_active = solutions_raw_active.drop(columns = {\n",
    "    'CRMBusinessArea',\n",
    "    'OpportunityID',\n",
    "   # 'OpportunityNumber',\n",
    "    'OpportunityName',\n",
    "    #'OpportunityStatusHistoryGroup',\n",
    "    #'OpportunityStatus', # forgot to remove in EDA script, can be fixed\n",
    "    #'CalendarDate',\n",
    "    'MaxWinChance',\n",
    "    'ActualWinChance',\n",
    "    'WinChanceDropFromMax',\n",
    "    'MinWinChance',\n",
    "    'stdWinChance',\n",
    "    'IsCurrentWinChanceMax',\n",
    "    'PeriodName',\n",
    "    'SecurityCountryName'\n",
    "\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Define the columns and their intended data types\n",
    "Dtypes_to_change = {\n",
    "    'TotalContractValueDKK': 'float',       \n",
    "    'AnnualContractValueDKK': 'float',\n",
    "    'MarginValueDKK': 'float',\n",
    "    #'PeriodName': 'category',\n",
    "    'MonthName': 'category',\n",
    "    'EmployeeName': 'category',\n",
    "    'Title': 'category',\n",
    "    'Department': 'category',\n",
    "    'Site': 'category',\n",
    "    'OpportunityStatusGroup': 'category',\n",
    "    'OpportunityConsciaCountry': 'category',\n",
    "    'OpportunitySalesTeam': 'category',\n",
    "    'SubType': 'category',\n",
    "    'DealSizeName': 'category',\n",
    "    'IndustryName': 'category',\n",
    "    'TechnologyName': 'category',\n",
    "    'YearName': 'category'\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "# Apply the dtype conversions\n",
    "for column, dtype in Dtypes_to_change.items():\n",
    "    try:\n",
    "        solutions_ml_active[column] = solutions_ml_active[column].astype(dtype)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not convert {column} to {dtype}: {e}\")\n",
    "\n",
    "\n",
    "solutions_ml_active['DaysBetweenCreateClose'] = solutions_ml_active['DaysBetweenCreateClose'].abs()\n",
    "\n",
    "solutions_ml_active = solutions_ml_active[solutions_ml_active['DaysBetweenCreateClose'] != 0]\n",
    "\n",
    "solutions_ml_active['EstimatedCloseDate'] = pd.to_datetime(solutions_ml_active['EstimatedCloseDate'].astype(str), format = '%Y%m%d')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fdbcf1-0f16-402b-a579-db8cdaf29718",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Removing IC\n",
    "solutions_ml = solutions_ml[~solutions_ml['IndustryName']\n",
    "                            .str.strip()\n",
    "                            .str.upper()\n",
    "                            .str.startswith('IC')]\n",
    "\n",
    "solutions_ml_active = solutions_ml_active[~solutions_ml_active['IndustryName']\n",
    "                            .str.strip()\n",
    "                            .str.upper()\n",
    "                            .str.startswith('IC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066b45ec-77c7-41b0-91ea-856787649857",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "## Descriptive statistics for numerical values prior to outlier-handling\n",
    "\n",
    "solutions_ml.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de5cd3-67fb-4fce-87e5-f2aa1217b2be",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Dine valgte numeriske features\n",
    "numvars = [\n",
    "    'TotalContractValueDKK',\n",
    "    'AnnualContractValueDKK',\n",
    "    'MarginValueDKK',\n",
    "    'DaysBetweenCreateClose',\n",
    "]\n",
    "\n",
    "# Opret subplots: 4 rækker, 1 kolonne\n",
    "fig, axes = plt.subplots(nrows=len(numvars), ncols=1, figsize=(12, 4*len(numvars)))\n",
    "\n",
    "for i, col in enumerate(numvars):\n",
    "    ax = axes[i]\n",
    "    sns.histplot(solutions_ml[col], bins=30, kde=False, ax=ax)\n",
    "    \n",
    "    # Formater x-aksen til “normale tal” med tusind-separator\n",
    "    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x):,}'))\n",
    "    \n",
    "    ax.set_title(f'Distribution af {col} forud for outlier håndtering')\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel('Antal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49a6278-2675-4946-8df2-aaf09a504e68",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "solutions_outlier_free = solutions_ml.copy()\n",
    "\n",
    "for var in numvars:\n",
    "    high_q = solutions_ml[var].quantile(0.98)\n",
    "    low_q = solutions_ml[var].quantile(0.02)\n",
    "\n",
    "    if var == \"DaysBetweenCreateClose\":\n",
    "        # Kun øvre cutoff for denne variabel\n",
    "        solutions_outlier_free = solutions_outlier_free[\n",
    "            solutions_outlier_free[var] <= high_q\n",
    "        ]\n",
    "    else:\n",
    "        # Normal 2%-98% cutoff\n",
    "        solutions_outlier_free = solutions_outlier_free[\n",
    "            (solutions_outlier_free[var] >= low_q) &\n",
    "            (solutions_outlier_free[var] <= high_q)\n",
    "        ]\n",
    "\n",
    "summary_før = solutions_ml[numvars].describe().T\n",
    "summary_efter = solutions_outlier_free[numvars].describe().T\n",
    "\n",
    "print(\"Før fjernet outliers:\\n\", summary_før)\n",
    "print(\"\\nEfter outliers:\\n\", summary_efter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f80eee-67b0-4224-9fa8-a68464fafc3d",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Dine valgte numeriske features\n",
    "numvars = [\n",
    "    'TotalContractValueDKK',\n",
    "    'AnnualContractValueDKK',\n",
    "    'MarginValueDKK',\n",
    "    'DaysBetweenCreateClose'\n",
    "]\n",
    "\n",
    "# Opret subplots: 4 rækker, 1 kolonne\n",
    "fig, axes = plt.subplots(nrows=len(numvars), ncols=1, figsize=(12, 4*len(numvars)))\n",
    "\n",
    "for i, col in enumerate(numvars):\n",
    "    ax = axes[i]\n",
    "    sns.histplot(solutions_outlier_free[col], bins=30, kde=False, ax=ax)\n",
    "    \n",
    "    # Formater x-aksen til “normale tal” med tusind-separator\n",
    "    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x):,}'))\n",
    "    \n",
    "    ax.set_title(f'Histogram of {col}')\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ae4c9d-8c99-40d6-af56-1b7f2e76470d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "for var in numvars:\n",
    "    high_q = solutions_ml[var].quantile(0.98)\n",
    "    low_q = solutions_ml[var].quantile(0.02)\n",
    "\n",
    "    if var == \"DaysBetweenCreateClose\":\n",
    "        # Kun øvre outliers fjernes\n",
    "        solutions_ml = solutions_ml[solutions_ml[var] <= high_q]\n",
    "    else:\n",
    "        # Fjern både nedre og øvre outliers\n",
    "        solutions_ml = solutions_ml[\n",
    "            (solutions_ml[var] >= low_q) & \n",
    "            (solutions_ml[var] <= high_q)\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc8930b-9086-470c-b10e-a8fe74f46d40",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "#### Tester kategoriske variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cat_cols = solutions_ml.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(cat_cols), ncols=1, figsize=(14, 5 * len(cat_cols)))\n",
    "\n",
    "if len(cat_cols) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, col in enumerate(cat_cols):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Freq table\n",
    "    freq = solutions_ml[col].value_counts(dropna=False)\n",
    "    perc = solutions_ml[col].value_counts(normalize=True, dropna=False) * 100\n",
    "    \n",
    "    # combination\n",
    "    freq_df = (\n",
    "        pd.DataFrame({'count': freq, 'percent': perc})\n",
    "        .sort_values('percent', ascending=False)\n",
    "    )\n",
    "    \n",
    "    # Barplot\n",
    "    sns.barplot(\n",
    "        x=freq_df.index.astype(str),\n",
    "        y=freq_df['percent'],\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f\"Kategorisk fordeling for {col}\")\n",
    "    ax.set_ylabel(\"Procent (%)\")\n",
    "    ax.set_xlabel(col)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # % label\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:.1f}%'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1f0860-4847-43bd-b698-6f434911b927",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Vi opelever enkelte kategorier med en enstydelig meget dominerede variabel, derfor fjerner vi:\n",
    "    # - Title\n",
    "    # - Department\n",
    "    # - Site\n",
    "    # - Der kan argumenteres for OpportunitySalesteam, med en enstydning repræsenteret kategori på ~ 60%\n",
    "\n",
    "\n",
    "solutions_ml = solutions_ml.drop(columns = [\n",
    "   \n",
    "    'Title', 'Department', 'Site', 'IndustryName', 'OpportunitySalesTeam'\n",
    "\n",
    "])\n",
    "\n",
    "solutions_ml_active = solutions_ml_active.drop(columns = [\n",
    "   \n",
    "    'Title', 'Department', 'Site', 'IndustryName', 'OpportunitySalesTeam'\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d16187-df57-4f65-9880-ff9de9f815ac",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#### Feature engineering more variables to capture trends not present within the data as of now ####\n",
    "\n",
    "# mapping for month-column\n",
    "\n",
    "month_map = {\n",
    "    \"January\": 1, \"February\": 2, \"March\": 3,\n",
    "    \"April\": 4, \"May\": 5, \"June\": 6, \"July\": 7, \"August\": 8,\n",
    "    \"September\": 9, \"October\": 10, \"November\": 11, \"December\": 12\n",
    "}\n",
    "\n",
    "# For closed opportunities\n",
    "solutions_ml['TCV_Margin_Ratio'] = solutions_ml['MarginValueDKK'] / solutions_ml['TotalContractValueDKK']\n",
    "solutions_ml['TCV_Margin_Ratio'].replace([np.inf, -np.inf], 0, inplace=True)\n",
    "solutions_ml['MonthNum'] = solutions_ml['MonthName'].map(month_map)\n",
    "solutions_ml['MonthNum'] = solutions_ml['MonthNum'].astype(int)\n",
    "solutions_ml['Quarter'] = ((solutions_ml['MonthNum'] -1) // 3 + 1)\n",
    "solutions_ml['Is_EOQ'] = solutions_ml['MonthNum'].isin([3,6,9,12]).astype(int)\n",
    "\n",
    "# For open opportunities\n",
    "solutions_ml_active['TCV_Margin_Ratio'] = solutions_ml_active['MarginValueDKK'] / solutions_ml_active['TotalContractValueDKK']\n",
    "solutions_ml_active['MonthNum'] = solutions_ml_active['MonthName'].map(month_map)\n",
    "solutions_ml_active['MonthNum'] = solutions_ml_active['MonthNum'].astype(int)\n",
    "solutions_ml_active['Quarter'] = ((solutions_ml_active['MonthNum'] -1) // 3 + 1)\n",
    "solutions_ml_active['Is_EOQ'] = solutions_ml_active['MonthNum'].isin([3,6,9,12]).astype(int)\n",
    "\n",
    "# Cumulative Employee features\n",
    "    # As the data needs to be cumulative, i need to concat the closed + open dataset together again\n",
    "        # this is a lazy fix. The better fix is to redo some of the previous filtering to allow for introductoin of feature engineering earlier on in the script\n",
    "\n",
    "samlet_sol = pd.concat([solutions_ml, solutions_ml_active], ignore_index = True)\n",
    "samlet_sol['PeriodMonth'] = pd.to_datetime(samlet_sol['PeriodDate'], format = \"%B %Y\").dt.to_period(\"M\")\n",
    "samlet_sol = samlet_sol.sort_values(['EmployeeName', 'PeriodMonth'])\n",
    "samlet_sol['IsClosed'] = (samlet_sol['OpportunityStatusGroup'] == \"Closed\").astype(int)\n",
    "samlet_sol['IsWon'] = (samlet_sol['OpportunityState'] == \"Won\").astype(int)\n",
    "\n",
    "samlet_sol['Total_closed_employee'] = (\n",
    "    samlet_sol.groupby('EmployeeName')\n",
    "    .apply(lambda g: g['IsClosed'].cumsum().shift(1).fillna(0))\n",
    "    .reset_index(level = 0, drop = True)\n",
    ")\n",
    "\n",
    "samlet_sol['Total_won_employee'] = (\n",
    "    samlet_sol.groupby('EmployeeName')\n",
    "    .apply(lambda g: g['IsWon'].cumsum().shift(1).fillna(0))\n",
    "    .reset_index(level = 0, drop = True)\n",
    ")\n",
    "\n",
    "\n",
    "no_employee_name = samlet_sol['EmployeeName'] == \"Not Available\"\n",
    "\n",
    "samlet_sol.loc[no_employee_name, [\n",
    "    'Total_closed_employee',\n",
    "    'Total_won_employee'\n",
    "]] = -1\n",
    "\n",
    "\n",
    "\n",
    "## Aggregating opportunities x monthly, then employee x monthly; creating monthly lag features\n",
    "\n",
    "samlet_sol = samlet_sol.sort_values(['PeriodMonth'])\n",
    "\n",
    "monthly_closed = (\n",
    "    samlet_sol.groupby('PeriodMonth')['IsClosed']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns = {'IsClosed': 'closed_per_month'})\n",
    ")\n",
    "\n",
    "monthly_closed['lag_1m_closed'] = monthly_closed['closed_per_month'].shift(1).fillna(0)\n",
    "monthly_closed['lag_3m_closed'] = monthly_closed['closed_per_month'].shift(3).fillna(0)\n",
    "monthly_closed['lag_year_closed'] = monthly_closed['closed_per_month'].shift(12).fillna(0)\n",
    "\n",
    "monthly_closed['sum_3m_closed'] = (\n",
    "    monthly_closed['closed_per_month']\n",
    "    .rolling(window=3, min_periods=1)\n",
    "    .sum()\n",
    "    .shift(1)\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "monthly_closed['sum_12m_closed'] = (\n",
    "    monthly_closed['closed_per_month']\n",
    "    .rolling(window=12, min_periods=1)\n",
    "    .sum()\n",
    "    .shift(1)\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "\n",
    "monthly_won = (\n",
    "    samlet_sol.groupby('PeriodMonth')['IsWon']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={'IsWon': 'won_per_month'})\n",
    ")\n",
    "\n",
    "monthly_won['lag_1m_won'] = monthly_won['won_per_month'].shift(1).fillna(0)\n",
    "monthly_won['lag_3m_won'] = monthly_won['won_per_month'].shift(3).fillna(0)\n",
    "monthly_won['lag_year_won'] = monthly_won['won_per_month'].shift(12).fillna(0)\n",
    "\n",
    "monthly_won['sum_3m_won'] = (\n",
    "    monthly_won['won_per_month']\n",
    "    .rolling(window=3, min_periods=1)\n",
    "    .sum()\n",
    "    .shift(1)\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "monthly_won['sum_12m_won'] = (\n",
    "    monthly_won['won_per_month']\n",
    "    .rolling(window=12, min_periods=1)\n",
    "    .sum()\n",
    "    .shift(1)\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "employee_monthly = (\n",
    "    samlet_sol.groupby(['EmployeeName', 'PeriodMonth'])['IsClosed']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns = {'IsClosed': 'closed_monthly_employee'})\n",
    ")\n",
    "\n",
    "employee_monthly['emp_lag_1m_closed'] = employee_monthly.groupby('EmployeeName')['closed_monthly_employee'].shift(1).fillna(0)\n",
    "employee_monthly['emp_lag_3m_closed'] = employee_monthly.groupby('EmployeeName')['closed_monthly_employee'].shift(3).fillna(0)\n",
    "employee_monthly['emp_lag_12m_closed'] = employee_monthly.groupby('EmployeeName')['closed_monthly_employee'].shift(12).fillna(0)\n",
    "\n",
    "employee_monthly['emp_sum_3m_closed'] = (\n",
    "    employee_monthly.groupby('EmployeeName')['closed_monthly_employee']\n",
    "    .rolling(window=3, min_periods=1)\n",
    "    .sum()\n",
    "    .shift(1)\n",
    "    .reset_index(level=0, drop=True)\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "employee_monthly['emp_sum_12m_closed'] = (\n",
    "    employee_monthly.groupby('EmployeeName')['closed_monthly_employee']\n",
    "    .rolling(window=12, min_periods=1)\n",
    "    .sum()\n",
    "    .shift(1)\n",
    "    .reset_index(level=0, drop=True)\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "\n",
    "employee_won_monthly = (\n",
    "    samlet_sol.groupby(['EmployeeName', 'PeriodMonth'])['IsWon']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={'IsWon': 'won_monthly_employee'})\n",
    ")\n",
    "\n",
    "employee_won_monthly['emp_lag_1m_won'] = employee_won_monthly.groupby('EmployeeName')['won_monthly_employee'].shift(1).fillna(0)\n",
    "employee_won_monthly['emp_lag_3m_won'] = employee_won_monthly.groupby('EmployeeName')['won_monthly_employee'].shift(3).fillna(0)\n",
    "employee_won_monthly['emp_lag_12m_won'] = employee_won_monthly.groupby('EmployeeName')['won_monthly_employee'].shift(12).fillna(0)\n",
    "\n",
    "employee_won_monthly['emp_sum_3m_won'] = (\n",
    "    employee_won_monthly.groupby('EmployeeName')['won_monthly_employee']\n",
    "    .rolling(window=3, min_periods=1)\n",
    "    .sum()\n",
    "    .shift(1)\n",
    "    .reset_index(level=0, drop=True)\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "employee_won_monthly['emp_sum_12m_won'] = (\n",
    "    employee_won_monthly.groupby('EmployeeName')['won_monthly_employee']\n",
    "    .rolling(window=12, min_periods=1)\n",
    "    .sum()\n",
    "    .shift(1)\n",
    "    .reset_index(level=0, drop=True)\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "##########################################################\n",
    "#### Merging lag & roll features back into samlet_sol ####\n",
    "##########################################################\n",
    "\n",
    "samlet_sol = samlet_sol.merge(\n",
    "    monthly_closed[\n",
    "        ['PeriodMonth',\n",
    "        'lag_1m_closed', 'lag_3m_closed', 'lag_year_closed',\n",
    "        'sum_3m_closed', 'sum_12m_closed']],\n",
    "    on='PeriodMonth',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "samlet_sol = samlet_sol.merge(\n",
    "    monthly_won[\n",
    "        ['PeriodMonth',\n",
    "        'lag_1m_won', 'lag_3m_won', 'lag_year_won',\n",
    "        'sum_3m_won', 'sum_12m_won']],\n",
    "    on='PeriodMonth',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "samlet_sol = samlet_sol.merge(\n",
    "    employee_monthly[\n",
    "        ['EmployeeName', 'PeriodMonth',\n",
    "        'closed_monthly_employee',\n",
    "        'emp_lag_1m_closed', 'emp_lag_3m_closed', 'emp_lag_12m_closed',\n",
    "        'emp_sum_3m_closed', 'emp_sum_12m_closed']],\n",
    "    on=['EmployeeName', 'PeriodMonth'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "samlet_sol = samlet_sol.merge(\n",
    "    employee_won_monthly[\n",
    "        ['EmployeeName', 'PeriodMonth',\n",
    "        'won_monthly_employee',\n",
    "        'emp_lag_1m_won', 'emp_lag_3m_won', 'emp_lag_12m_won',\n",
    "        'emp_sum_3m_won', 'emp_sum_12m_won']],\n",
    "    on=['EmployeeName', 'PeriodMonth'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Defaulting values to -1 in the instance of no stated EmployeeName, as i dont want the model to learn patterns around a non-existant Employee.\n",
    "\n",
    "emp_lag_roll_features = [\n",
    "    'emp_lag_1m_closed', 'emp_lag_3m_closed', 'emp_lag_12m_closed', \n",
    "    'emp_sum_3m_closed', 'emp_sum_12m_closed',\n",
    "    'emp_lag_1m_won', 'emp_lag_3m_won', 'emp_lag_12m_won',\n",
    "    'emp_sum_3m_won', 'emp_sum_12m_won'\n",
    "]\n",
    "samlet_sol.loc[samlet_sol['EmployeeName'] == \"Not Available\", emp_lag_roll_features] = -1\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "#### Merging back into solutions_ml & solutions_ml_active ####\n",
    "##############################################################\n",
    "\n",
    "lag_roll_features = [\n",
    "    'lag_1m_closed', 'lag_3m_closed', 'sum_3m_closed', 'sum_12m_closed',\n",
    "    'lag_1m_won', 'lag_3m_won', 'sum_3m_won', 'sum_12m_won',\n",
    "    'emp_lag_1m_closed', 'emp_lag_3m_closed', 'emp_lag_12m_closed', 'emp_sum_3m_closed', 'emp_sum_12m_closed',\n",
    "    'emp_lag_1m_won', 'emp_lag_3m_won', 'emp_lag_12m_won', 'emp_sum_3m_won', 'emp_sum_12m_won'\n",
    "]\n",
    "\n",
    "solutions_ml = solutions_ml.merge(\n",
    "    samlet_sol[['EmployeeName', 'OpportunityNumber'] + lag_roll_features],\n",
    "    on=['EmployeeName', 'OpportunityNumber'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "solutions_ml_active = solutions_ml_active.merge(\n",
    "    samlet_sol[['EmployeeName', 'OpportunityNumber'] + lag_roll_features],\n",
    "    on=['EmployeeName', 'OpportunityNumber'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Drop  columns used for feature engineering and filtering within the script.\n",
    "    # Likewise dropping the redundant closedate for each closed and open opportunities (Estimated for closed, actualclosedate for open)\n",
    "\n",
    "solutions_ml = solutions_ml.drop(columns = [\n",
    "    'MonthNum', 'EstimatedCloseDate', 'PeriodDate', 'CalendarDate', 'CreatedDate'\n",
    "])\n",
    "\n",
    "solutions_ml_active = solutions_ml_active.drop(columns = [\n",
    "   'MonthNum', 'ActualClosedDate', 'PeriodDate', 'CalendarDate', 'CreatedDate'\n",
    "])\n",
    "\n",
    "\n",
    "# To ensure same columns for machine learning, we need to rename the columns of ActualClosedDate and EstimatedCloseDate\n",
    "solutions_ml = solutions_ml.rename(columns = {'ActualClosedDate': 'CloseDate'})\n",
    "solutions_ml_active = solutions_ml_active.rename(columns = {'EstimatedCloseDate': 'CloseDate'})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d183654-03ad-4e3a-9d1b-a017daffc09c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Corrplot to check correlation between target var + numvars aswell as checking for multicol\n",
    "# Although decision trees are naturally prone to multicol it never hurts to test and understand the data more nuanced\n",
    "\n",
    "\n",
    "\n",
    "lag_roll_features = [\n",
    "    'lag_1m_closed', 'lag_3m_closed', 'sum_3m_closed', 'sum_12m_closed',\n",
    "    'lag_1m_won', 'lag_3m_won', 'sum_3m_won', 'sum_12m_won',\n",
    "    'emp_lag_1m_closed', 'emp_lag_3m_closed', 'emp_lag_12m_closed', 'emp_sum_3m_closed', 'emp_sum_12m_closed',\n",
    "    'emp_lag_1m_won', 'emp_lag_3m_won', 'emp_lag_12m_won', 'emp_sum_3m_won', 'emp_sum_12m_won'\n",
    "]\n",
    "\n",
    "corr_solutions = solutions_ml.copy()\n",
    "\n",
    "corr_solutions['OpportunityState'] = corr_solutions['OpportunityState'].map({\n",
    "    'Won': 1,\n",
    "    'Lost': 0\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "corr_df = corr_solutions[lag_roll_features]\n",
    "\n",
    "\n",
    "# Compute correlation matrix (Pearson by default)\n",
    "corr_matrix = corr_df.corr()\n",
    "\n",
    "# Plot\n",
    "\n",
    "fig,ax = plt.subplots(figsize = (10,10))\n",
    "\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype = bool), k = 1)\n",
    "\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    mask = mask,\n",
    "    annot = False,\n",
    "    fmt = \".2f\",\n",
    "    cmap = \"RdBu_r\",\n",
    "    center = 0,\n",
    "    vmin = -1,\n",
    "    vmax = 1,\n",
    "    square = True,\n",
    "    linewidth = 0.5,\n",
    "    annot_kws={\"size\": 8, \"color\": \"black\", \"weight\": \"bold\"},\n",
    "    ax = ax,\n",
    "    clip_on = False\n",
    ")\n",
    "\n",
    "plt.title(\"Korrelationsmatrice over lag / roll features\", fontsize = 14, fontweight = \"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d243f165-9d96-430a-8445-bac0dba6d8c0",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Heavy ocrrelation between a lot of the newly added lag / roll features; therefore we remove a lot of these features to maintain only a few\n",
    "\n",
    "features_to_keep = [\n",
    "    'sum_3m_won',\n",
    "    'sum_12m_won',\n",
    "    'emp_lag_1m_won',\n",
    "    'emp_lag_12m_won',\n",
    "    'emp_sum_3m_won'\n",
    "]\n",
    "\n",
    "# Drop alle de andre lag/roll features\n",
    "solutions_ml = solutions_ml.drop(columns=[col for col in lag_roll_features if col not in features_to_keep])\n",
    "solutions_ml_active = solutions_ml_active.drop(columns=[col for col in lag_roll_features if col not in features_to_keep])\n",
    "\n",
    "\n",
    "# Fjerner samtidigt andre korrelerede features;\n",
    "    # - AnnualContractValueDKK (korreleret med TCV)\n",
    "    # - Margin (har lavet TCV_To_Margin_Ratio variabel. Denne burde være redundant nu)\n",
    "\n",
    "solutions_ml = solutions_ml.drop(columns = [\n",
    "   # 'AnnualContractValueDKK'#,\n",
    "    #'MarginValueDKK'\n",
    "])\n",
    "\n",
    "solutions_ml_active = solutions_ml_active.drop(columns = [\n",
    "    #'AnnualContractValueDKK'#,\n",
    "    #'MarginValueDKK'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69f9604-269d-4599-9b4f-f2d8f5adbc9c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "## skubber dataframe til Lakehouse\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "#spark.createDataFrame(sales_flattened).write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"sales_flat\")\n",
    "        # Fix at a later point. not important now\n",
    "\n",
    "spark.createDataFrame(solutions_ml).write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"solutions_ml\")\n",
    "spark.createDataFrame(solutions_ml_active).write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"Active_opportunities\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c316058f-4bcb-449c-9f31-665277e6aacf",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Explorative Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2191957-6157-4ff1-93cc-03a8355fda11",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# As the categorical dtypes default to objects once converted back and forth between spark/pandas dataframes, its needed to once again transform the dtypes\n",
    "\n",
    "for col in solutions_ml.select_dtypes(include = 'object').columns:\n",
    "    solutions_ml[col] = solutions_ml[col].astype('category')\n",
    "\n",
    "solutions_ml['Is_EOQ'] = solutions_ml['Is_EOQ'].astype('category') \n",
    "solutions_ml['Quarter'] = solutions_ml['Quarter'].astype('category') \n",
    "\n",
    "\n",
    "# Likewise some of the correlation testing and plotting requires the target variable to numerical\n",
    "\n",
    "solutions_ml['OpportunityState_num'] = solutions_ml['OpportunityState'].map({'Won': 1, 'Lost': 0})\n",
    "\n",
    "\n",
    "# Other dependencies for EDA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "import logging\n",
    "\n",
    "# Suppress all logging messages below CRITICAL\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "\n",
    "import statsmodels.api as sm \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf53357-a15d-4656-8c5f-99a39dacdc8b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "def plot_opportunitystate_counts_and_proportions(df, target=\"OpportunityState\"):\n",
    "    \n",
    "    counts = df[target].value_counts()\n",
    "    proportions = counts / counts.sum()\n",
    "\n",
    "    custom_colors = [\"#5B2C6F\", \"#F5B041\"]  # color\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    sns.barplot(\n",
    "        x=counts.index, \n",
    "        y=counts.values, \n",
    "        palette=custom_colors, \n",
    "        ax=axes[0], \n",
    "        edgecolor=\"black\"\n",
    "    )\n",
    "    axes[0].set_title(\"Fordeling af Target-variabel: OpportunityState (antal)\")\n",
    "    axes[0].set_xlabel(target)\n",
    "    axes[0].set_ylabel(\"Antal\")\n",
    "\n",
    "    for p in axes[0].patches:\n",
    "        height = p.get_height()\n",
    "        axes[0].annotate(\n",
    "            f\"{height}\", \n",
    "            (p.get_x() + p.get_width()/2, height),\n",
    "            ha=\"center\", \n",
    "            va=\"bottom\", \n",
    "            fontsize=11\n",
    "        )\n",
    "\n",
    "    sns.barplot(\n",
    "        x=proportions.index, \n",
    "        y=proportions.values, \n",
    "        palette=custom_colors, \n",
    "        ax=axes[1], \n",
    "        edgecolor=\"black\"\n",
    "    )\n",
    "    axes[1].set_title(\"Fordeling af Target-variabel: OpportunityState (andel)\")\n",
    "    axes[1].set_xlabel(target)\n",
    "    axes[1].set_ylabel(\"Andel\")\n",
    "\n",
    "    for p in axes[1].patches:\n",
    "        height = p.get_height()\n",
    "        axes[1].annotate(\n",
    "            f\"{height*100:.1f}%\", \n",
    "            (p.get_x() + p.get_width()/2, height),\n",
    "            ha=\"center\", \n",
    "            va=\"bottom\", \n",
    "            fontsize=11\n",
    "        )\n",
    "\n",
    "    fig.suptitle(\n",
    "        \"Der er en stærk overvægt af vundne salgsmuligheder i datasættet\",\n",
    "        fontsize=16,\n",
    "        weight=\"bold\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    fig.text(0.02, -0.02, \"Kilde: Egen analyse baseret på solutions_ml\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plot_opportunitystate_counts_and_proportions(solutions_ml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3951611e-b110-44d3-a9f6-54d7f2484652",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "def kde_three_features(df, target=\"OpportunityState\"):\n",
    "    features = [\"TotalContractValueDKK\", \"AnnualContractValueDKK\", \"MarginValueDKK\"]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(30 , 10))        #     20, 6 før\n",
    "\n",
    "    for ax, feature in zip(axes, features):\n",
    "        sns.kdeplot(\n",
    "            data=df,\n",
    "            x=feature,\n",
    "            hue=target,\n",
    "            fill=True,\n",
    "            common_norm=False,\n",
    "            alpha=0.5,\n",
    "            linewidth=2,\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"Distribution af {feature}\", fontsize=13, weight=\"bold\")\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.set_ylabel(\"Densitet\")\n",
    "\n",
    "        # removing scientific notation\n",
    "        ax.ticklabel_format(style='plain', useOffset=False, axis='both')\n",
    "\n",
    "    fig.suptitle(\"Den samme tendens er gældende i de finansielle tal\", fontsize=16, weight=\"bold\")\n",
    "    fig.text(0.02, -0.02, \"Kilde: Egen analyse baseret på solutions_ml\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "kde_three_features(solutions_ml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3928a9d8-1b9a-46df-a58d-37fea6b90bef",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "df = solutions_ml.copy()\n",
    "\n",
    "target = \"OpportunityState_num\"\n",
    "\n",
    "\n",
    "numvars = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numvars = [v for v in numvars if v != target]\n",
    "\n",
    "def kde_numeric_feature(df, feature, target=\"OpportunityState_num\"):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    sns.kdeplot(\n",
    "        data=df,\n",
    "        x=feature,\n",
    "        hue=target,\n",
    "        fill=True,\n",
    "        common_norm=False,\n",
    "        alpha=0.5,\n",
    "        linewidth=2\n",
    "    )\n",
    "\n",
    "    plt.title(f\"KDE-distribution af {feature} fordelt på target\", fontsize=14, weight=\"bold\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Densitet\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for feature in numvars:\n",
    "    print(f\"Plotter KDE for: {feature}\")\n",
    "    kde_numeric_feature(df, feature, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c3ea72-e053-48e6-a2b8-243cd0e92c9c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "\n",
    "def cat_counts_and_proportions(df, col, target=\"OpportunityState\", top_n=10):\n",
    "    contingency = pd.crosstab(df[col].astype(str), df[target])\n",
    "\n",
    "    # Top N sorting\n",
    "    contingency[\"__total__\"] = contingency.sum(axis=1)\n",
    "    contingency = contingency.sort_values(\"__total__\", ascending=False)\n",
    "\n",
    "    if contingency.shape[0] > top_n:\n",
    "        other = contingency.iloc[top_n:].sum()\n",
    "        other.name = \"Other\"\n",
    "        contingency = pd.concat([contingency.iloc[:top_n], other.to_frame().T])\n",
    "\n",
    "    contingency_counts = contingency.drop(columns=\"__total__\")\n",
    "    contingency_prop = contingency_counts.div(contingency_counts.sum(axis=1), axis=0)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        1, 2,\n",
    "        figsize=(18, max(6, contingency_counts.shape[0] * 0.5)),\n",
    "        sharey=True\n",
    "    )\n",
    "\n",
    "    palette = sns.color_palette(\"tab20\")\n",
    "\n",
    "    # COUNTS\n",
    "    contingency_counts.plot(\n",
    "        kind=\"barh\",\n",
    "        stacked=True,\n",
    "        ax=axes[0],\n",
    "        color=palette\n",
    "    )\n",
    "    axes[0].invert_yaxis()\n",
    "    axes[0].set_title(f\"{col} fordelt på {target} (Counts)\", fontsize=14, weight=\"bold\")\n",
    "    axes[0].set_xlabel(\"Antal\")\n",
    "    axes[0].set_ylabel(col)\n",
    "\n",
    "    # PROPORTIONS\n",
    "    contingency_prop.plot(\n",
    "        kind=\"barh\",\n",
    "        stacked=True,\n",
    "        ax=axes[1],\n",
    "        color=palette\n",
    "    )\n",
    "    axes[1].invert_yaxis()\n",
    "    axes[1].set_title(f\"{col} fordelt på {target} (Proportioner)\", fontsize=14, weight=\"bold\")\n",
    "    axes[1].set_xlabel(\"Proportion\")\n",
    "    axes[1].set_ylabel(\"\")\n",
    "    axes[1].legend(title=target, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "categorical_cols = solutions_ml.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "target = \"OpportunityState\"\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col == target:\n",
    "        continue  # Skip target var\n",
    "    print(f\"Plotter: {col}\")\n",
    "    cat_counts_and_proportions(solutions_ml, col, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417c225-d3e9-4275-a727-179c00c3bf07",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# First doing the typical inspection, making sure everything is as it is supposed to post cleaning. \n",
    "\n",
    "solutions_ml.head()\n",
    "solutions_ml.tail()\n",
    "solutions_ml.info()\n",
    "solutions_ml.shape\n",
    "solutions_ml.columns\n",
    "solutions_ml.dtypes\n",
    "\n",
    "# checking NA / NaN's \n",
    "\n",
    "solutions_ml.isna().sum()\n",
    "solutions_ml.isna().sum().sum()\n",
    "solutions_ml.isna().mean()\n",
    "\n",
    "# Checking for duplicates\n",
    "\n",
    "solutions_ml.duplicated.any()\n",
    "solutions_ml.duplicated.sum()\n",
    "#  potentally extract duplicated rows with solutions_ml[solutions_ml.duplicated()]\n",
    "solutions_ml.drop_duplicates()\n",
    "\n",
    "# Summary stats\n",
    "\n",
    "solutions_ml.describe()\n",
    "    # in case it misses some columns due to mixed datatypes; \n",
    "solutions_ml.describe(include = 'all')\n",
    "solutions_ml.nunique()\n",
    "solutions_ml['OpportunityState'].value_counts()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba4f6b1-84c6-4494-a91b-b569c5c18fcc",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Exploring distributions and visualizations of given target + features\n",
    "    # esp. looking for tendencies that could indicate correlation or atleast a relationship with the target_val\n",
    "    # Also remember doing for example chi^2 + logreg to give initial indications of statistical significance \n",
    "\n",
    "solutions_ml.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc15b9-bbd4-417b-a3c8-50050bc26a0b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Since multicol is only for numvars i use chi^2 for catvars\n",
    "\n",
    "\n",
    "# CHI^2\n",
    "\n",
    "\n",
    "target = \"OpportunityState\"\n",
    "\n",
    "catvars = [col for col in solutions_ml.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "           if col not in ['OpportunityStatusGroup', 'OpportunityNumber']]\n",
    "\n",
    "\n",
    "chi2_results = []\n",
    "\n",
    "for col in catvars:\n",
    "    contingency = pd.crosstab(solutions_ml[col], solutions_ml[target])\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "    \n",
    "    chi2_results.append({\n",
    "        \"variable\": col,\n",
    "        \"chi2\": chi2,\n",
    "        \"p_value\": p,\n",
    "        \"degrees_of_freedom\": dof\n",
    "    })\n",
    "\n",
    "chi2_df = pd.DataFrame(chi2_results).sort_values(\"p_value\")\n",
    "\n",
    "\n",
    "chi2_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1365e60f-4b85-479f-b44e-507187d7c85c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "df = solutions_ml.copy()\n",
    "\n",
    "# Target: skal være 0/1 for logit\n",
    "y = df[\"OpportunityState_num\"]\n",
    "\n",
    "\n",
    "numvars = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numvars = [v for v in numvars if v not in [\"OpportunityState_num\"]] \n",
    "\n",
    "\n",
    "def logistic_reg_plot(df, feature, y):\n",
    "    X = df[[feature]].copy()\n",
    "\n",
    "   \n",
    "    X_sm = sm.add_constant(X) \n",
    "    sm_model = sm.Logit(y, X_sm).fit(disp=False)\n",
    "\n",
    "   \n",
    "    sk_model = LogisticRegression()\n",
    "    sk_model.fit(X_sm, y)  \n",
    "\n",
    "    # Range til sigmoid\n",
    "    x_range = np.linspace(X[feature].min(), X[feature].max(), 300)\n",
    "    X_pred = pd.DataFrame({\n",
    "        \"const\": 1,\n",
    "        feature: x_range\n",
    "    })\n",
    "    y_pred_prob = sm_model.predict(X_pred)\n",
    "\n",
    "  \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x_range, y_pred_prob, linewidth=3, color=\"steelblue\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Probability (Won)\")\n",
    "    plt.title(f\"Logistic Regression Sigmoid Curve for {feature}\", fontsize=14, weight=\"bold\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return sm_model\n",
    "\n",
    "\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for feature in numvars:\n",
    "    print(\"\\n=====================================\")\n",
    "    print(f\"LOGISTIC REGRESSION FOR: {feature}\")\n",
    "    print(\"=====================================\\n\")\n",
    "\n",
    "    model = logistic_reg_plot(df, feature, y)\n",
    "    all_results[feature] = model\n",
    "\n",
    "    # Statsmodels summary\n",
    "    print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d280468-1a1e-4d88-b549-fcc53a8a9c3c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Corrplot to check correlation between target var + numvars aswell as checking for multicol\n",
    "# Although decision trees are naturally prone to multicol it never hurts to test and understand the data more nuanced\n",
    "\n",
    "\n",
    "corr_solutions = solutions_ml.copy()\n",
    "\n",
    "corr_solutions['OpportunityState'] = corr_solutions['OpportunityState'].map({\n",
    "    'Won': 1,\n",
    "    'Lost': 0\n",
    "})\n",
    "\n",
    "\n",
    "numvars = [f for f in corr_solutions.columns if f not in catvars\n",
    "and f not in ['OpportunityStatusGroup', 'OpportunityNumber', 'CloseDate']]\n",
    "numvars.append('OpportunityState')\n",
    "\n",
    "corr_df = corr_solutions[numvars]\n",
    "\n",
    "\n",
    "# Compute correlation matrix (Pearson by default)\n",
    "corr_matrix = corr_df.corr()\n",
    "\n",
    "# Plot\n",
    "\n",
    "fig,ax = plt.subplots(figsize = (10,8))\n",
    "\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype = bool), k = 1)  \n",
    "\n",
    "sns.heatmap(\n",
    "    corr_matrix,    \n",
    "    mask = mask,\n",
    "    annot = False,\n",
    "    fmt = \".2f\",\n",
    "    cmap = \"RdBu_r\",\n",
    "    center = 0,\n",
    "    vmin = -1,\n",
    "    vmax = 1,\n",
    "    square = True,\n",
    "    linewidth = 0.5,\n",
    "    annot_kws={\"size\": 8, \"color\": \"black\", \"weight\": \"bold\"},\n",
    "    ax = ax,\n",
    "    clip_on = False\n",
    ")\n",
    "\n",
    "plt.title(\"Korrelationsmatrice over datasættets numeriske variable\", fontsize = 14, fontweight = \"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67cdf39-3ae9-495a-b23a-b7ed06951454",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Data vizualisation ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cde5f69-1ecf-4284-88f7-4e741f06d70b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "def stacked_counts_and_proportions(df, col, target=\"OpportunityState\", top_n=15):\n",
    "\n",
    "    contingency = pd.crosstab(df[col].astype(str), df[target])\n",
    "\n",
    "    contingency[\"__total__\"] = contingency.sum(axis=1)\n",
    "    contingency = contingency.sort_values(\"__total__\", ascending=False).head(top_n)\n",
    "    contingency_counts = contingency.drop(columns=\"__total__\")\n",
    "\n",
    "    contingency_prop = contingency_counts.div(contingency_counts.sum(axis=1), axis=0)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        1, 2,\n",
    "        figsize=(18, max(6, top_n * 0.5)),\n",
    "        sharey=True\n",
    "    )\n",
    "\n",
    "    palette = sns.color_palette(\"tab20\")\n",
    "\n",
    "    contingency_counts.plot(\n",
    "        kind=\"barh\",\n",
    "        stacked=True,\n",
    "        ax=axes[0],\n",
    "        color=palette\n",
    "    )\n",
    "    axes[0].invert_yaxis()\n",
    "    axes[0].set_title(f\"Top {top_n} {col} fordelt på {target} (Counts)\", fontsize=14, weight=\"bold\")\n",
    "    axes[0].set_xlabel(\"Antal\")\n",
    "    axes[0].set_ylabel(col)\n",
    "\n",
    "    contingency_prop.plot(\n",
    "        kind=\"barh\",\n",
    "        stacked=True,\n",
    "        ax=axes[1],\n",
    "        color=palette\n",
    "    )\n",
    "    axes[1].invert_yaxis()\n",
    "    axes[1].set_title(f\"Top {top_n} {col} fordelt på {target} (Procent)\", fontsize=14, weight=\"bold\")\n",
    "    axes[1].set_xlabel(\"Procent\")\n",
    "    axes[1].set_ylabel(\"\")\n",
    "\n",
    "    axes[1].legend(title=target, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"Distribution af kategorien '{col}' opdelt på target-variablen '{target}'\",\n",
    "        fontsize=16\n",
    "    )\n",
    "    fig.text(0.02, -0.02, \"Kilde: Egen analyse baseret på solutions_ml\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stacked_counts_and_proportions(solutions_ml, 'EmployeeName')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d97fdb-5d18-4230-a743-f5fe225541ed",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "catvars = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "exclude = ['OpportunityStatusGroup', 'OpportunityNumber', 'OpportunityState']\n",
    "catvars = [c for c in catvars if c not in exclude]\n",
    "\n",
    "for col in catvars:\n",
    "    stacked_counts_and_proportions(df, col, target=\"OpportunityState\", top_n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44869ca-769e-4ce8-9af0-b9608ffdacdc",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "## Med udgangspunkt i foregående analyse, fremvises følgende plots som værende af interesse\n",
    "# ['TotalContractValueDKK', AnnualContractValueDKK, 'MarginValueDKK', 'DaysBetweenCreateClose']\n",
    "# ['MonthName', 'EmployeeName', 'OpportunityConsciaCountry' (top_n == 7), 'DealSizeName', 'TechnologyName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2abdd7-5f39-46a5-b956-e2aa389df7cd",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Target var count / distri \n",
    "\n",
    "plot_opportunitystate_counts_and_proportions(solutions_ml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7e440d-faef-472c-9694-0953a5144030",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# KDE PLOT af de 3 finansielle drenge\n",
    "\n",
    "kde_three_features(solutions_ml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044dbad9-3fa4-49a8-8ccb-5f646a9ee358",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# KDE PLOT af DaysBetweenCreateClose\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "numeric_var = \"DaysBetweenCreateClose\"\n",
    "target = \"OpportunityState\"\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.kdeplot(\n",
    "    data=solutions_ml,\n",
    "    x=numeric_var,\n",
    "    hue=target,\n",
    "    fill=True,\n",
    "    common_norm=False,\n",
    "    alpha=0.5,\n",
    "    linewidth=2\n",
    ")\n",
    "\n",
    "plt.title(\"Langt de fleste salgsmuligheder lukkes forud for 100 dage. Tabte salgsmulighder er meget mere spredte\",\n",
    "          fontsize=15, weight=\"bold\")\n",
    "plt.xlabel(\"DaysBetweenCreateClose\")\n",
    "plt.ylabel(\"Densitet\")\n",
    "\n",
    "plt.figtext(0.01, -0.02, \"Kilde: Egen analyse baseret på solutions_ml\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b57561-ad27-4f37-b1c5-cae26d2e4fda",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Month\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "def monthname_counts_and_proportions(df, col=\"MonthName\", target=\"OpportunityState\"):\n",
    "\n",
    "    month_order = [\n",
    "        \"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
    "        \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"\n",
    "    ]\n",
    "\n",
    "    df[col] = pd.Categorical(df[col], categories=month_order, ordered=True)\n",
    "\n",
    "    contingency = pd.crosstab(df[col], df[target])\n",
    "\n",
    "    contingency = contingency.loc[month_order].dropna(how=\"all\")\n",
    "\n",
    "    contingency_prop = contingency.div(contingency.sum(axis=1), axis=0)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        1, 2,\n",
    "        figsize=(18, 8),\n",
    "        sharey=True\n",
    "    )\n",
    "\n",
    "    palette = sns.color_palette(\"tab20\")\n",
    "\n",
    "    # ---- COUNTS ----\n",
    "    contingency.plot(\n",
    "        kind=\"barh\",\n",
    "        stacked=True,\n",
    "        ax=axes[0],\n",
    "        color=palette\n",
    "    )\n",
    "    axes[0].invert_yaxis()\n",
    "    axes[0].set_title(f\"{col} fordelt på {target} (Antal)\", fontsize=14, weight=\"bold\")\n",
    "    axes[0].set_xlabel(\"Antal\")\n",
    "    axes[0].set_ylabel(col)\n",
    "\n",
    "    contingency_prop.plot(\n",
    "        kind=\"barh\",\n",
    "        stacked=True,\n",
    "        ax=axes[1],\n",
    "        color=palette\n",
    "    )\n",
    "    axes[1].invert_yaxis()\n",
    "    axes[1].set_title(f\"{col} fordelt på {target} (Andel)\", fontsize=14, weight=\"bold\")\n",
    "    axes[1].set_xlabel(\"Andel\")\n",
    "    axes[1].set_ylabel(\"\")\n",
    "\n",
    "    axes[1].legend(title=target, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"Der er usædvanligt store sæsonudsving i antal lukninger af salgsmuligheder\",\n",
    "        fontsize=16,\n",
    "        weight=\"bold\"\n",
    "    )\n",
    "    fig.text(0.02, -0.02, \"Kilde: Egen analyse baseret på solutions_ml\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "monthname_counts_and_proportions(solutions_ml, col=\"MonthName\", target=\"OpportunityState\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2943f20c-7c39-4134-8e04-ad67da121436",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "Employee_IDs = spark.read.format(\"delta\").load(\"cantshow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db3beca-fe7b-4a7a-88ee-55dc548ee348",
   "metadata": {
    "editable": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "run_control": {
     "frozen": false
    }
   },
   "outputs": [],
   "source": [
    "solutions_ml = solutions_ml.toPandas()\n",
    "Employee_IDs = Employee_IDs.toPandas()\n",
    "\n",
    "Employee_IDs_unique = Employee_IDs.drop_duplicates(subset=[\"EmployeeName\"])\n",
    "\n",
    "name_to_id = Employee_IDs_unique.set_index(\"EmployeeName\")[\"EmployeeID\"].to_dict()\n",
    "\n",
    "solutions_ml[\"EmployeeID\"] = solutions_ml[\"EmployeeName\"].map(name_to_id)\n",
    "\n",
    "unmatched = solutions_ml[solutions_ml[\"EmployeeID\"].isna()][\"EmployeeName\"].unique()\n",
    "print(\"Unmatched names:\", unmatched)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d818d9-5266-462e-b6c0-09b2a988458c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Barplot af EmployeeName\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "def employee_counts_and_proportions(df, col=\"EmployeeID\", target=\"OpportunityState\", top_n=10):\n",
    "\n",
    "    contingency = pd.crosstab(df[col].astype(str), df[target])\n",
    "\n",
    "    contingency[\"__total__\"] = contingency.sum(axis=1)\n",
    "    contingency = contingency.sort_values(\"__total__\", ascending=False).head(top_n)\n",
    "    contingency_counts = contingency.drop(columns=\"__total__\")\n",
    "\n",
    "    contingency_prop = contingency_counts.div(contingency_counts.sum(axis=1), axis=0)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        1, 2,\n",
    "        figsize=(18, max(6, top_n * 0.5)),\n",
    "        sharey=True\n",
    "    )\n",
    "\n",
    "    palette = sns.color_palette(\"tab20\")\n",
    "\n",
    "    contingency_counts.plot(\n",
    "        kind=\"barh\",\n",
    "        stacked=True,\n",
    "        ax=axes[0],\n",
    "        color=palette\n",
    "    )\n",
    "    axes[0].invert_yaxis()\n",
    "    axes[0].set_title(f\"{col} fordelt på {target} (Antal)\", fontsize=14, weight=\"bold\")\n",
    "    axes[0].set_xlabel(\"Antal\")\n",
    "    axes[0].set_ylabel(col)\n",
    "\n",
    "    contingency_prop.plot(\n",
    "        kind=\"barh\",\n",
    "        stacked=True,\n",
    "        ax=axes[1],\n",
    "        color=palette\n",
    "    )\n",
    "    axes[1].invert_yaxis()\n",
    "    axes[1].set_title(f\"{col} fordelt på {target} (Andel)\", fontsize=14, weight=\"bold\")\n",
    "    axes[1].set_xlabel(\"Andel\")\n",
    "    axes[1].set_ylabel(\"\")\n",
    "\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"Der er stor forskel på medarbejdernes andel af vundne salgsmuligheder\",\n",
    "        fontsize=16,\n",
    "        weight=\"bold\"\n",
    "    )\n",
    "    fig.text(0.02, -0.02, \"Kilde: Egen analyse baseret på solutions_ml\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "employee_counts_and_proportions(solutions_ml, col=\"EmployeeID\", target=\"OpportunityState\", top_n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c9f623-b7ac-49de-9487-28fdfd9026f7",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Barplot af OpportunityConsciaCountry (top_n == 7)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "def country_counts_and_proportions(df, col=\"OpportunityConsciaCountry\", target=\"OpportunityState\", top_n=7):\n",
    "\n",
    "    contingency = pd.crosstab(df[col].astype(str), df[target])\n",
    "\n",
    "    contingency[\"__total__\"] = contingency.sum(axis=1)\n",
    "    contingency = contingency.sort_values(\"__total__\", ascending=False).head(top_n)\n",
    "    contingency_counts = contingency.drop(columns=\"__total__\")\n",
    "\n",
    "    contingency_prop = contingency_counts.div(contingency_counts.sum(axis=1), axis=0)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        1, 2,\n",
    "        figsize=(22, max(6, top_n * 0.5)),\n",
    "        sharey=True\n",
    "    )\n",
    "\n",
    "    palette = sns.color_palette(\"tab20\")\n",
    "\n",
    "    contingency_counts.plot(\n",
    "        kind=\"barh\",\n",
    "        stacked=True,\n",
    "        ax=axes[0],\n",
    "        color=palette\n",
    "    )\n",
    "    axes[0].invert_yaxis()\n",
    "    axes[0].set_title(f\"{col} fordelt på {target} (Antal)\", fontsize=14, weight=\"bold\")\n",
    "    axes[0].set_xlabel(\"Antal\")\n",
    "    axes[0].set_ylabel(col)\n",
    "\n",
    "    contingency_prop.plot(\n",
    "        kind=\"barh\",\n",
    "        stacked=True,\n",
    "        ax=axes[1],\n",
    "        color=palette\n",
    "    )\n",
    "    axes[1].invert_yaxis()\n",
    "    axes[1].set_title(f\"{col} fordelt på {target} (Andel)\", fontsize=14, weight=\"bold\")\n",
    "    axes[1].set_xlabel(\"Andel\")\n",
    "    axes[1].set_ylabel(\"\")\n",
    "\n",
    "    axes[1].legend(title=target, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"Der opleves en stor variation i både antal såvel som andel af lukkede salgsmuligheder fordelt på land\",\n",
    "        fontsize=16,\n",
    "        weight=\"bold\"\n",
    "    )\n",
    "    fig.text(0.02, -0.02, \"Kilde: Egen analyse baseret på solutions_ml\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "country_counts_and_proportions(solutions_ml, col=\"OpportunityConsciaCountry\", target=\"OpportunityState\", top_n=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66914da5-62e8-4852-aaf9-6209a9d271bb",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Barplot af DealSizeName\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "def dealsize_counts_and_proportions(df, col=\"DealSizeName\", target=\"OpportunityState\"):\n",
    "\n",
    "    contingency = pd.crosstab(df[col].astype(str), df[target])\n",
    "\n",
    "    contingency[\"__total__\"] = contingency.sum(axis=1)\n",
    "    contingency = contingency.sort_values(\"__total__\", ascending=False)\n",
    "    contingency_counts = contingency.drop(columns=\"__total__\")\n",
    "\n",
    "    contingency_prop = contingency_counts.div(contingency_counts.sum(axis=1), axis=0)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        1, 2,\n",
    "        figsize=(18, max(6, len(contingency) * 0.5)),\n",
    "        sharey=True\n",
    "    )\n",
    "\n",
    "    palette = sns.color_palette(\"tab20\")\n",
    "\n",
    "    contingency_counts.plot(\n",
    "        kind=\"barh\",\n",
    "        stacked=True,\n",
    "        ax=axes[0],\n",
    "        color=palette\n",
    "    )\n",
    "    axes[0].invert_yaxis()\n",
    "    axes[0].set_title(f\"{col} fordelt på {target} (Antal)\", fontsize=14, weight=\"bold\")\n",
    "    axes[0].set_xlabel(\"Andel\")\n",
    "    axes[0].set_ylabel(col)\n",
    "\n",
    "    contingency_prop.plot(\n",
    "        kind=\"barh\",\n",
    "        stacked=True,\n",
    "        ax=axes[1],\n",
    "        color=palette\n",
    "    )\n",
    "    axes[1].invert_yaxis()\n",
    "    axes[1].set_title(f\"{col} fordelt på {target} (Andel)\", fontsize=14, weight=\"bold\")\n",
    "    axes[1].set_xlabel(\"Andel\")\n",
    "    axes[1].set_ylabel(\"\")\n",
    "\n",
    "    axes[1].legend(title=target, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"Deals < 50.000 kr. fremstår mest frekvente og med den stærkeste relative succesrate.\",\n",
    "        fontsize=16,\n",
    "        weight=\"bold\"\n",
    "    )\n",
    "    fig.text(0.02, -0.02, \"Kilde: Egen analyse baseret på solutions_ml\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dealsize_counts_and_proportions(solutions_ml, col=\"DealSizeName\", target=\"OpportunityState\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff0b1a2-c4c9-4267-8be6-3494129ca2fc",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Barplot af TechnologyName\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "def technology_counts_and_proportions(df, col=\"TechnologyName\", target=\"OpportunityState\", top_n=5):\n",
    "\n",
    "    contingency = pd.crosstab(df[col].astype(str), df[target])\n",
    "\n",
    "    contingency[\"__total__\"] = contingency.sum(axis=1)\n",
    "    contingency = contingency.sort_values(\"__total__\", ascending=False).head(top_n)\n",
    "    contingency_counts = contingency.drop(columns=\"__total__\")\n",
    "\n",
    "    contingency_prop = contingency_counts.div(contingency_counts.sum(axis=1), axis=0)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        1, 2,\n",
    "        figsize=(18, max(6, top_n * 0.6)),\n",
    "        sharey=True\n",
    "    )\n",
    "\n",
    "    palette = sns.color_palette(\"tab20\")\n",
    "\n",
    "    contingency_counts.plot(\n",
    "        kind=\"barh\",\n",
    "        stacked=True,\n",
    "        ax=axes[0],\n",
    "        color=palette\n",
    "    )\n",
    "    axes[0].invert_yaxis()\n",
    "    axes[0].set_title(f\"{col} fordelt på {target} (Antal)\", fontsize=14, weight=\"bold\")\n",
    "    axes[0].set_xlabel(\"Antal\")\n",
    "    axes[0].set_ylabel(col)\n",
    "\n",
    "    contingency_prop.plot(\n",
    "        kind=\"barh\",\n",
    "        stacked=True,\n",
    "        ax=axes[1],\n",
    "        color=palette\n",
    "    )\n",
    "    axes[1].invert_yaxis()\n",
    "    axes[1].set_title(f\"{col} fordelt på {target} (Andel)\", fontsize=14, weight=\"bold\")\n",
    "    axes[1].set_xlabel(\"Andel\")\n",
    "    axes[1].set_ylabel(\"\")\n",
    "\n",
    "    axes[1].legend(title=target, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"Network er det klart mest frekvente forretningsområde, og har den stærkste relative succesrate \",\n",
    "        fontsize=16,\n",
    "        weight=\"bold\"\n",
    "    )\n",
    "    fig.text(0.02, -0.02, \"Kilde: Egen analyse baseret på solutions_ml\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "technology_counts_and_proportions(solutions_ml, col=\"TechnologyName\", target=\"OpportunityState\", top_n=5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b5fb16-af1d-48a9-ad7a-79b73fd69a6e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# KDE PLOT af DaysBetweenCreateClose\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "numeric_var = \"TCV_Margin_Ratio\"\n",
    "target = \"OpportunityState\"\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.kdeplot(\n",
    "    data=solutions_ml,\n",
    "    x=numeric_var,\n",
    "    hue=target,\n",
    "    fill=True,\n",
    "    common_norm=False,\n",
    "    alpha=0.5,\n",
    "    linewidth=2\n",
    ")\n",
    "\n",
    "plt.title(\"Langt de fleste salgsmuligheder lukkes forud for 100 dage. Tabte salgsmulighder er meget mere spredte\",\n",
    "          fontsize=15, weight=\"bold\")\n",
    "plt.xlabel(\"DaysBetweenCreateClose\")\n",
    "plt.ylabel(\"Densitet\")\n",
    "\n",
    "plt.figtext(0.01, -0.02, \"Kilde: Egen analyse baseret på solutions_ml\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb17b58-f814-4ad9-bba9-3f5da11b94ec",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "Quarter\n",
    "EOQ\n",
    "SubType \n",
    "TCV_Margin_Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21028b15-609b-416b-9002-805ecf0635f5",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Barplot af SubType\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "def technology_counts_and_proportions(df, col=\"SubType\", target=\"OpportunityState\", top_n=5):\n",
    "\n",
    "    contingency = pd.crosstab(df[col].astype(str), df[target])\n",
    "\n",
    "    contingency[\"__total__\"] = contingency.sum(axis=1)\n",
    "    contingency = contingency.sort_values(\"__total__\", ascending=False).head(top_n)\n",
    "    contingency_counts = contingency.drop(columns=\"__total__\")\n",
    "\n",
    "    contingency_prop = contingency_counts.div(contingency_counts.sum(axis=1), axis=0)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        1, 2,\n",
    "        figsize=(18, max(6, top_n * 0.6)),\n",
    "        sharey=True\n",
    "    )\n",
    "\n",
    "    palette = sns.color_palette(\"tab20\")\n",
    "\n",
    "    contingency_counts.plot(\n",
    "        kind=\"barh\",\n",
    "        stacked=True,\n",
    "        ax=axes[0],\n",
    "        color=palette\n",
    "    )\n",
    "    axes[0].invert_yaxis()\n",
    "    axes[0].set_title(f\"{col} fordelt på {target} (Antal)\", fontsize=14, weight=\"bold\")\n",
    "    axes[0].set_xlabel(\"Antal\")\n",
    "    axes[0].set_ylabel(col)\n",
    "\n",
    "    contingency_prop.plot(\n",
    "        kind=\"barh\",\n",
    "        stacked=True,\n",
    "        ax=axes[1],\n",
    "        color=palette\n",
    "    )\n",
    "    axes[1].invert_yaxis()\n",
    "    axes[1].set_title(f\"{col} fordelt på {target} (Andel)\", fontsize=14, weight=\"bold\")\n",
    "    axes[1].set_xlabel(\"Andel\")\n",
    "    axes[1].set_ylabel(\"\")\n",
    "\n",
    "    axes[1].legend(title=target, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"Der opleves større udsving i den relative succesrate for de forskellige forretningsundertyper \",\n",
    "        fontsize=16,\n",
    "        weight=\"bold\"\n",
    "    )\n",
    "    fig.text(0.02, -0.02, \"Kilde: Egen analyse baseret på solutions_ml\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "technology_counts_and_proportions(solutions_ml, col=\"SubType\", target=\"OpportunityState\", top_n=5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d25a6-f681-4dbb-8017-fe18524b6322",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Barplot af Quarter\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "def technology_counts_and_proportions(df, col=\"Quarter\", target=\"OpportunityState\", top_n=5):\n",
    "\n",
    "    contingency = pd.crosstab(df[col].astype(str), df[target])\n",
    "\n",
    "    contingency[\"__total__\"] = contingency.sum(axis=1)\n",
    "    contingency = contingency.sort_values(\"__total__\", ascending=False).head(top_n)\n",
    "    contingency_counts = contingency.drop(columns=\"__total__\")\n",
    "\n",
    "    contingency_prop = contingency_counts.div(contingency_counts.sum(axis=1), axis=0)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        1, 2,\n",
    "        figsize=(18, max(6, top_n * 0.6)),\n",
    "        sharey=True\n",
    "    )\n",
    "\n",
    "    palette = sns.color_palette(\"tab20\")\n",
    "\n",
    "    contingency_counts.plot(\n",
    "        kind=\"barh\",\n",
    "        stacked=True,\n",
    "        ax=axes[0],\n",
    "        color=palette\n",
    "    )\n",
    "    axes[0].invert_yaxis()\n",
    "    axes[0].set_title(f\"{col} fordelt på {target} (Antal)\", fontsize=14, weight=\"bold\")\n",
    "    axes[0].set_xlabel(\"Antal\")\n",
    "    axes[0].set_ylabel(col)\n",
    "\n",
    "    contingency_prop.plot(\n",
    "        kind=\"barh\",\n",
    "        stacked=True,\n",
    "        ax=axes[1],\n",
    "        color=palette\n",
    "    )\n",
    "    axes[1].invert_yaxis()\n",
    "    axes[1].set_title(f\"{col} fordelt på {target} (Andel)\", fontsize=14, weight=\"bold\")\n",
    "    axes[1].set_xlabel(\"Andel\")\n",
    "    axes[1].set_ylabel(\"\")\n",
    "\n",
    "    axes[1].legend(title=target, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"Omkring halvdelen af alle salg bliver lukket i det første kvartal. \",\n",
    "        fontsize=16,\n",
    "        weight=\"bold\"\n",
    "    )\n",
    "    fig.text(0.02, -0.02, \"Kilde: Egen analyse baseret på solutions_ml\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "technology_counts_and_proportions(solutions_ml, col=\"Quarter\", target=\"OpportunityState\", top_n=5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed27d75-a546-4df7-9cf7-a2ccb8ee585a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Barplot af Is_EOQ\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "def technology_counts_and_proportions(df, col=\"Is_EOQ\", target=\"OpportunityState\", top_n=5):\n",
    "\n",
    "    contingency = pd.crosstab(df[col].astype(str), df[target])\n",
    "\n",
    "    contingency[\"__total__\"] = contingency.sum(axis=1)\n",
    "    contingency = contingency.sort_values(\"__total__\", ascending=False).head(top_n)\n",
    "    contingency_counts = contingency.drop(columns=\"__total__\")\n",
    "\n",
    "    contingency_prop = contingency_counts.div(contingency_counts.sum(axis=1), axis=0)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        1, 2,\n",
    "        figsize=(18, max(6, top_n * 0.6)),\n",
    "        sharey=True\n",
    "    )\n",
    "\n",
    "    palette = sns.color_palette(\"tab20\")\n",
    "\n",
    "    contingency_counts.plot(\n",
    "        kind=\"barh\",\n",
    "        stacked=True,\n",
    "        ax=axes[0],\n",
    "        color=palette\n",
    "    )\n",
    "    axes[0].invert_yaxis()\n",
    "    axes[0].set_title(f\"{col} fordelt på {target} (Antal)\", fontsize=14, weight=\"bold\")\n",
    "    axes[0].set_xlabel(\"Antal\")\n",
    "    axes[0].set_ylabel(col)\n",
    "\n",
    "    contingency_prop.plot(\n",
    "        kind=\"barh\",\n",
    "        stacked=True,\n",
    "        ax=axes[1],\n",
    "        color=palette\n",
    "    )\n",
    "    axes[1].invert_yaxis()\n",
    "    axes[1].set_title(f\"{col} fordelt på {target} (Andel)\", fontsize=14, weight=\"bold\")\n",
    "    axes[1].set_xlabel(\"Andel\")\n",
    "    axes[1].set_ylabel(\"\")\n",
    "\n",
    "    axes[1].legend(title=target, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"Flest salg bliver lukket i slutningen af kvartaler, trods en meget ens relativ succesrate.\",\n",
    "        fontsize=16,\n",
    "        weight=\"bold\"\n",
    "    )\n",
    "    fig.text(0.02, -0.02, \"Kilde: Egen analyse baseret på solutions_ml\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "technology_counts_and_proportions(solutions_ml, col=\"Is_EOQ\", target=\"OpportunityState\", top_n=5)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "43b504ef-d5b9-4d75-9d65-bfc320a8736c",
    "default_lakehouse_name": "ml_curate_lakehouse",
    "default_lakehouse_workspace_id": "19522171-0292-4a1f-854f-4941b77c2765",
    "known_lakehouses": [
     {
      "id": "43b504ef-d5b9-4d75-9d65-bfc320a8736c"
     },
     {
      "id": "00f737c5-1567-4877-b859-26c76ece3d60"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "synapse_pyspark",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
